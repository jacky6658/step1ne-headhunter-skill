#!/usr/bin/env python3
"""
104äººåŠ›éŠ€è¡Œè·ç¼ºçˆ¬èŸ² v2
ç”¨é€”ï¼šæœå°‹è·ç¼ºï¼Œæå–å…¬å¸å’Œè·ä½è³‡è¨Šï¼ˆä½¿ç”¨ JavaScript eval æå–ï¼‰
"""

import subprocess
import json
import re
import sys
import tempfile
from datetime import datetime

def run_browser_command(cmd):
    """åŸ·è¡Œ agent-browser æŒ‡ä»¤"""
    result = subprocess.run(cmd, shell=True, capture_output=True, text=True)
    return result.stdout

def run_js_in_browser(js_code):
    """åœ¨ç€è¦½å™¨ä¸­åŸ·è¡Œ JavaScript ä¸¦è¿”å›çµæœ"""
    # å°‡ JavaScript å­˜æˆè‡¨æ™‚æª”æ¡ˆ
    with tempfile.NamedTemporaryFile(mode='w', suffix='.js', delete=False) as f:
        f.write(js_code)
        js_file = f.name
    
    # åŸ·è¡Œ
    result = run_browser_command(f'agent-browser eval "$(cat {js_file})"')
    
    # æ¸…ç†
    import os
    os.unlink(js_file)
    
    return result

def log_debug(message):
    """å¯«å…¥ debug æ—¥èªŒ"""
    with open("/tmp/104-scraper-v2-debug.log", 'a', encoding='utf-8') as log:
        log.write(f"[{datetime.now()}] {message}\n")

def search_104_jobs(keyword, max_results=20):
    """æœå°‹ 104 è·ç¼º"""
    log_debug(f"ğŸ” æœå°‹: {keyword}")
    
    # é–‹å•Ÿæœå°‹é é¢
    url = f"https://www.104.com.tw/jobs/search/?keyword={keyword}"
    run_browser_command(f'agent-browser open "{url}"')
    
    # ç­‰å¾…è¼‰å…¥
    run_browser_command('agent-browser wait --load networkidle --timeout 10000')
    
    # ä½¿ç”¨ JavaScript æå–è·ç¼ºè³‡æ–™
    js_code = """
    (() => {
        const jobs = [];
        const jobCards = document.querySelectorAll('article[data-job-custno]');
        
        jobCards.forEach((card, index) => {
            if (index >= """ + str(max_results) + """) return;
            
            const titleEl = card.querySelector('a[data-job-link-type="1"]');
            const companyEl = card.querySelector('a[data-job-link-type="2"]');
            const locationEl = card.querySelector('[data-v-5e3f8c9f].job-list-tag-location');
            const salaryEl = card.querySelector('[data-v-5e3f8c9f].job-list-tag-salary');
            
            jobs.push({
                title: titleEl ? titleEl.innerText.trim() : 'N/A',
                url: titleEl ? titleEl.href : '',
                company: companyEl ? companyEl.innerText.trim() : 'N/A',
                location: locationEl ? locationEl.innerText.trim() : 'N/A',
                salary: salaryEl ? salaryEl.innerText.trim() : 'N/A'
            });
        });
        
        return JSON.stringify(jobs);
    })();
    """
    
    # åŸ·è¡Œ JavaScript
    result = run_js_in_browser(js_code)
    
    log_debug(f"JavaScript result: {result[:200]}...")
    
    # é—œé–‰ç€è¦½å™¨
    run_browser_command('agent-browser close')
    
    # è§£æçµæœ
    try:
        jobs = json.loads(result.strip())
        log_debug(f"âœ… æ‰¾åˆ° {len(jobs)} å€‹è·ç¼º")
        return jobs
    except Exception as e:
        log_debug(f"âŒ è§£æå¤±æ•—: {e}, result={result[:500]}")
        return []

def get_company_contact(job_url):
    """å¾è·ç¼ºé é¢æå–å…¬å¸è¯çµ¡æ–¹å¼"""
    log_debug(f"ğŸ“ è¨ªå•è·ç¼ºé é¢: {job_url}")
    
    run_browser_command(f'agent-browser open "{job_url}"')
    run_browser_command('agent-browser wait --load networkidle --timeout 10000')
    
    # æå–å…¬å¸è³‡è¨Šçš„ JavaScript
    js_code = """
    (() => {
        const info = {
            phone: null,
            email: null,
            website: null,
            companyUrl: null
        };
        
        // æå–é›»è©±
        const phoneEl = document.querySelector('[data-v-7e8bc2b0].company-phone a');
        if (phoneEl) {
            info.phone = phoneEl.innerText.trim();
        }
        
        // æå– Emailï¼ˆå¦‚æœæœ‰ï¼‰
        const emailEl = document.querySelector('[data-v-7e8bc2b0].company-email a');
        if (emailEl) {
            info.email = emailEl.innerText.trim();
        }
        
        // æå–å…¬å¸ç¶²å€
        const websiteEl = document.querySelector('[data-v-7e8bc2b0].company-website a');
        if (websiteEl) {
            info.website = websiteEl.href;
        }
        
        // æå–å…¬å¸é é¢é€£çµ
        const companyLinkEl = document.querySelector('a[href*="/company/"]');
        if (companyLinkEl) {
            info.companyUrl = companyLinkEl.href;
        }
        
        return JSON.stringify(info);
    })();
    """
    
    result = run_js_in_browser(js_code)
    
    # é—œé–‰ç€è¦½å™¨
    run_browser_command('agent-browser close')
    
    try:
        contact_info = json.loads(result.strip())
        log_debug(f"âœ… æå–è³‡è¨Š: Phone={contact_info.get('phone')}, Email={contact_info.get('email')}, Website={contact_info.get('website')}")
        return contact_info
    except Exception as e:
        log_debug(f"âŒ æå–å¤±æ•—: {e}")
        return {"phone": None, "email": None, "website": None, "companyUrl": None}

def scrape_company_website(website_url):
    """çˆ¬å–å…¬å¸å®˜ç¶²ï¼Œæå–è¯çµ¡æ–¹å¼"""
    if not website_url or not website_url.startswith('http'):
        return {"phone": None, "email": None}
    
    log_debug(f"ğŸŒ è¨ªå•å®˜ç¶²: {website_url}")
    
    # å˜—è©¦æ‰¾ã€Œè¯çµ¡æˆ‘å€‘ã€é é¢
    contact_urls = [
        website_url,
        f"{website_url.rstrip('/')}/contact",
        f"{website_url.rstrip('/')}/contact-us",
        f"{website_url.rstrip('/')}/about"
    ]
    
    for url in contact_urls:
        try:
            run_browser_command(f'agent-browser open "{url}"')
            run_browser_command('agent-browser wait --load networkidle --timeout 5000')
            
            # æå–é›»è©±å’Œ Email
            js_code = """
            (() => {
                const text = document.body.innerText;
                
                // æå–é›»è©±ï¼ˆå°ç£æ ¼å¼ï¼‰
                const phoneMatch = text.match(/(\\d{2,4}[-\\s]?\\d{3,4}[-\\s]?\\d{3,4})/);
                
                // æå– Email
                const emailMatch = text.match(/[\\w\\.-]+@[\\w\\.-]+\\.\\w+/);
                
                return JSON.stringify({
                    phone: phoneMatch ? phoneMatch[0] : null,
                    email: emailMatch ? emailMatch[0] : null
                });
            })();
            """
            
            result = run_js_in_browser(js_code)
            
            # é—œé–‰ç€è¦½å™¨
            run_browser_command('agent-browser close')
            
            contact_info = json.loads(result.strip())
            
            if contact_info.get('phone') or contact_info.get('email'):
                log_debug(f"âœ… å®˜ç¶²æ‰¾åˆ°è³‡è¨Š: {contact_info}")
                return contact_info
        except:
            continue
    
    log_debug(f"âš ï¸ å®˜ç¶²æœªæ‰¾åˆ°è¯çµ¡æ–¹å¼")
    return {"phone": None, "email": None}

def main():
    """ä¸»ç¨‹å¼"""
    keyword = sys.argv[1] if len(sys.argv) > 1 else "backend engineer"
    max_results = int(sys.argv[2]) if len(sys.argv) > 2 else 20
    
    log_debug(f"é–‹å§‹è™•ç†: {keyword}, æ•¸é‡: {max_results}")
    
    # æ­¥é©Ÿ 1ï¼šæœå°‹è·ç¼º
    jobs = search_104_jobs(keyword, max_results)
    
    if not jobs:
        print("[]")
        return
    
    # æ­¥é©Ÿ 2ï¼šæå–æ¯å€‹è·ç¼ºçš„å…¬å¸è¯çµ¡æ–¹å¼
    detailed_jobs = []
    
    for job in jobs:
        log_debug(f"è™•ç†è·ç¼º: {job.get('title')}")
        
        # å¾è·ç¼ºé é¢æå–è¯çµ¡æ–¹å¼
        contact_info = get_company_contact(job.get('url', ''))
        
        # å¦‚æœæ²’æœ‰é›»è©±æˆ– Emailï¼Œå˜—è©¦çˆ¬å®˜ç¶²
        if (not contact_info.get('phone') or not contact_info.get('email')) and contact_info.get('website'):
            website_contact = scrape_company_website(contact_info.get('website'))
            
            if not contact_info.get('phone'):
                contact_info['phone'] = website_contact.get('phone')
            if not contact_info.get('email'):
                contact_info['email'] = website_contact.get('email')
        
        # æ•´åˆè³‡æ–™
        detailed_job = {
            "company": job.get('company', 'N/A'),
            "job_title": job.get('title', 'N/A'),
            "location": job.get('location', 'N/A'),
            "salary": job.get('salary', 'N/A'),
            "url": job.get('url', ''),
            "phone": contact_info.get('phone') or "å¾…æŸ¥",
            "email": contact_info.get('email') or "å¾…æŸ¥",
            "website": contact_info.get('website') or "å¾…æŸ¥",
            "contact_person": "æ‚¨å¥½",
            "status": "å¾…è¯ç¹«"
        }
        
        detailed_jobs.append(detailed_job)
        log_debug(f"âœ… å®Œæˆ: {detailed_job['company']}")
    
    # è¼¸å‡º JSON
    print(json.dumps(detailed_jobs, ensure_ascii=False, indent=2))
    
    log_debug(f"âœ… å…¨éƒ¨å®Œæˆï¼Œå…±è™•ç† {len(detailed_jobs)} å®¶å…¬å¸")

if __name__ == "__main__":
    main()
