#!/usr/bin/env python3
"""
GitHub äººæ‰æœå°‹å·¥å…·
ç”¨é€”ï¼šæœå°‹ GitHub é–‹ç™¼è€…ï¼Œæå–è¯çµ¡è³‡è¨Šç”¨æ–¼æ‹›å‹Ÿ
"""

import subprocess
import json
import re
import sys
import time
from datetime import datetime

def run_browser(cmd):
    """åŸ·è¡Œ agent-browser æŒ‡ä»¤"""
    result = subprocess.run(cmd, shell=True, capture_output=True, text=True, timeout=30)
    return result.stdout.strip()

def search_github_users(location="taipei", language="python", min_repos=5, min_followers=10, max_results=20):
    """
    æœå°‹ GitHub ç”¨æˆ¶
    
    Args:
        location: åœ°é» (taipei, taiwan, etc.)
        language: ç¨‹å¼èªè¨€ (python, javascript, java, etc.)
        min_repos: æœ€å°‘ repo æ•¸
        min_followers: æœ€å°‘ followers æ•¸
        max_results: æœ€å¤šå›å‚³æ•¸é‡
    """
    print(f"ğŸ” æœå°‹æ¢ä»¶: location:{location} language:{language} repos:>{min_repos} followers:>{min_followers}")
    
    # æ§‹å»ºæœå°‹ URL
    query = f"location:{location}"
    if language:
        query += f" language:{language}"
    if min_repos:
        query += f" repos:>{min_repos}"
    if min_followers:
        query += f" followers:>{min_followers}"
    
    url = f"https://github.com/search?q={query.replace(' ', '+')}&type=users"
    
    # é–‹å•Ÿæœå°‹é é¢
    run_browser(f'agent-browser open "{url}"')
    time.sleep(2)
    
    # å–å¾—å¿«ç…§
    snapshot = run_browser('agent-browser snapshot -i --json')
    
    try:
        data = json.loads(snapshot)
        refs = data.get('data', {}).get('refs', {})
    except:
        print("âŒ ç„¡æ³•è§£ææœå°‹çµæœ")
        return []
    
    # æå–ç”¨æˆ¶å
    users = []
    for ref_id, ref_data in refs.items():
        name = ref_data.get('name', '')
        role = ref_data.get('role', '')
        
        # å°‹æ‰¾ Follow æŒ‰éˆ•å‰é¢çš„ç”¨æˆ¶åé€£çµ
        if role == 'link' and name and not name.startswith('Page') and name != 'Follow':
            # æª¢æŸ¥æ˜¯å¦ç‚ºç”¨æˆ¶åæ ¼å¼ (é€šå¸¸æ˜¯å°å¯«+æ•¸å­—)
            if re.match(r'^[a-zA-Z0-9_-]+$', name) and len(name) < 40:
                # æ’é™¤å¸¸è¦‹éç”¨æˆ¶åçš„é€£çµ
                if name.lower() not in ['code', 'repositories', 'issues', 'pull', 'discussions', 
                                         'users', 'more', 'javascript', 'python', 'java', 'html',
                                         'c++', 'c#', 'css', 'php', 'homepage', 'pricing', 'sign',
                                         'advanced', 'search', 'sponsorable']:
                    if name not in [u.get('username') for u in users]:
                        users.append({'username': name, 'ref': ref_id})
        
        if len(users) >= max_results:
            break
    
    print(f"ğŸ“Š æ‰¾åˆ° {len(users)} å€‹é–‹ç™¼è€…")
    return users

def get_user_profile(username):
    """
    å–å¾—ç”¨æˆ¶è©³ç´°è³‡æ–™
    
    Args:
        username: GitHub ç”¨æˆ¶å
    
    Returns:
        dict: ç”¨æˆ¶è³‡æ–™
    """
    print(f"  ğŸ“„ è®€å– {username} çš„è³‡æ–™...")
    
    # é–‹å•Ÿç”¨æˆ¶é é¢
    run_browser(f'agent-browser open "https://github.com/{username}"')
    time.sleep(1)
    
    # å–å¾—é é¢å…§å®¹
    snapshot = run_browser('agent-browser snapshot -i --json')
    
    profile = {
        'username': username,
        'url': f'https://github.com/{username}',
        'name': None,
        'bio': None,
        'location': None,
        'email': None,
        'company': None,
        'website': None,
        'twitter': None,
        'repos': None,
        'followers': None,
    }
    
    try:
        data = json.loads(snapshot)
        refs = data.get('data', {}).get('refs', {})
        snapshot_text = data.get('data', {}).get('snapshot', '')
        
        for ref_id, ref_data in refs.items():
            name = ref_data.get('name', '')
            
            # æå–å„ç¨®è³‡è¨Š
            if '@' in name and '.' in name:  # Email
                profile['email'] = name
            elif name.startswith('http'):  # Website
                if 'twitter.com' in name or 'x.com' in name:
                    profile['twitter'] = name
                else:
                    profile['website'] = name
            elif 'followers' in name.lower():
                # å˜—è©¦æå– followers æ•¸é‡
                match = re.search(r'(\d+(?:,\d+)*(?:\.\d+)?[kK]?)', name)
                if match:
                    profile['followers'] = match.group(1)
        
        # å¾ snapshot æ–‡æœ¬ä¸­æå–æ›´å¤šè³‡è¨Š
        lines = snapshot_text.split('\n')
        for line in lines:
            if 'location' in line.lower() and profile['location'] is None:
                # å˜—è©¦æå–ä½ç½®
                match = re.search(r'"([^"]+)"', line)
                if match:
                    profile['location'] = match.group(1)
                    
    except Exception as e:
        print(f"  âš ï¸ è§£æ {username} è³‡æ–™æ™‚å‡ºéŒ¯: {e}")
    
    return profile

def search_and_extract(location="taipei", language="python", min_repos=5, min_followers=10, max_results=10, get_details=True):
    """
    å®Œæ•´æœå°‹æµç¨‹ï¼šæœå°‹ + æå–è©³ç´°è³‡æ–™
    """
    print("=" * 60)
    print("ğŸ¯ GitHub äººæ‰æœå°‹å·¥å…·")
    print("=" * 60)
    
    # æœå°‹ç”¨æˆ¶
    users = search_github_users(location, language, min_repos, min_followers, max_results)
    
    if not users:
        print("âŒ æ²’æœ‰æ‰¾åˆ°ç¬¦åˆæ¢ä»¶çš„ç”¨æˆ¶")
        return []
    
    results = []
    
    if get_details:
        print(f"\nğŸ“‹ æ­£åœ¨æå– {len(users)} ä½é–‹ç™¼è€…çš„è©³ç´°è³‡æ–™...\n")
        for i, user in enumerate(users):
            profile = get_user_profile(user['username'])
            results.append(profile)
            
            # é¡¯ç¤ºé€²åº¦
            print(f"  [{i+1}/{len(users)}] {profile['username']}")
            if profile.get('email'):
                print(f"       ğŸ“§ {profile['email']}")
            if profile.get('location'):
                print(f"       ğŸ“ {profile['location']}")
            
            time.sleep(0.5)  # é¿å…å¤ªå¿«è¢«æ“‹
    else:
        results = [{'username': u['username'], 'url': f"https://github.com/{u['username']}"} for u in users]
    
    # é—œé–‰ç€è¦½å™¨
    run_browser('agent-browser close')
    
    return results

def main():
    """ä¸»å‡½æ•¸"""
    # é è¨­åƒæ•¸
    location = sys.argv[1] if len(sys.argv) > 1 else "taipei"
    language = sys.argv[2] if len(sys.argv) > 2 else "python"
    max_results = int(sys.argv[3]) if len(sys.argv) > 3 else 10
    
    results = search_and_extract(
        location=location,
        language=language,
        min_repos=5,
        min_followers=10,
        max_results=max_results,
        get_details=True
    )
    
    # è¼¸å‡ºçµæœ
    print("\n" + "=" * 60)
    print("ğŸ“Š æœå°‹çµæœæ‘˜è¦")
    print("=" * 60)
    
    # æœ‰ email çš„
    with_email = [r for r in results if r.get('email')]
    print(f"\nâœ… æœ‰ Email çš„é–‹ç™¼è€…: {len(with_email)} äºº")
    for r in with_email:
        print(f"   â€¢ {r['username']} - {r['email']}")
    
    # æ‰€æœ‰çµæœ
    print(f"\nğŸ“‹ å…¨éƒ¨é–‹ç™¼è€…: {len(results)} äºº")
    for r in results:
        print(f"   â€¢ {r['username']} - {r['url']}")
    
    # å­˜æª”
    output_file = f"/tmp/github-talent-{location}-{language}-{datetime.now().strftime('%Y%m%d-%H%M%S')}.json"
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(results, f, ensure_ascii=False, indent=2)
    
    print(f"\nğŸ’¾ çµæœå·²å­˜è‡³: {output_file}")

if __name__ == "__main__":
    main()
