#!/usr/bin/env python3
"""
æ‰¹é‡è§£æå±¥æ­· PDFï¼Œæå–å§“åã€è·ä½ã€æŠ€èƒ½ç­‰è³‡è¨Š
"""
import os
import json
import re
from pathlib import Path
import pdfplumber

# å·²è™•ç†çš„æ–‡ä»¶ï¼ˆä¸é‡è¤‡è™•ç†ï¼‰
PROCESSED_FILES = [
    'file_638', 'file_639', 'file_640', 'file_641', 'file_642', 'file_643',
    'file_644', 'file_645', 'file_646', 'file_647', 'file_648'
]

def extract_text_from_pdf(pdf_path):
    """ä½¿ç”¨ pdfplumber æå– PDF æ–‡å­—"""
    try:
        with pdfplumber.open(pdf_path) as pdf:
            text = ''
            for page in pdf.pages[:3]:  # åªè®€å‰ 3 é ï¼ˆå±¥æ­·é€šå¸¸ä¸è¶…é 3 é ï¼‰
                text += page.extract_text() or ''
            return text
    except Exception as e:
        print(f"âš ï¸  PDF è§£æå¤±æ•—: {e}")
        return ""

def extract_name(text):
    """å¾å±¥æ­·ä¸­æå–å§“å"""
    # LinkedIn å±¥æ­·é€šå¸¸ç¬¬ä¸€è¡Œæ˜¯å§“å
    lines = [l.strip() for l in text.split('\n') if l.strip()]
    if not lines:
        return "æœªçŸ¥"
    
    # ç¬¬ä¸€å€‹éç©ºè¡Œé€šå¸¸æ˜¯å§“å
    first_line = lines[0]
    
    # éæ¿¾æ˜é¡¯ä¸æ˜¯å§“åçš„ï¼ˆå¤ªé•·ã€åŒ…å«ç‰¹å®šé—œéµå­—ï¼‰
    if len(first_line) > 50 or any(kw in first_line.lower() for kw in ['resume', 'cv', 'curriculum', 'profile']):
        # å˜—è©¦ç¬¬äºŒè¡Œ
        if len(lines) > 1:
            return lines[1][:50]  # é™åˆ¶é•·åº¦
    
    return first_line[:50]

def extract_position(text):
    """æå–è·ä½"""
    # å¸¸è¦‹è·ä½é—œéµå­—
    finance_positions = [
        'finance manager', 'financial manager', 'accounting manager',
        'finance controller', 'chief financial officer', 'cfo',
        'finance director', 'finance and accounting manager'
    ]
    
    text_lower = text.lower()
    for pos in finance_positions:
        if pos in text_lower:
            return pos.title()
    
    return "Finance Manager"

def extract_skills(text):
    """æå–æŠ€èƒ½é—œéµå­—"""
    skills = []
    skill_keywords = [
        'sap', 'excel', 'quickbooks', 'erp', 'financial accounting',
        'taxation', 'payroll', 'budgeting', 'forecasting', 'auditing',
        'ifrs', 'gaap', 'cost accounting', 'management accounting',
        'accounts payable', 'accounts receivable', 'general ledger'
    ]
    
    text_lower = text.lower()
    for skill in skill_keywords:
        if skill in text_lower:
            skills.append(skill.upper() if len(skill) <= 4 else skill.title())
    
    return ', '.join(skills[:5]) if skills else "å¾…ç¢ºèª"

def parse_resume(pdf_path):
    """è§£æå–®å€‹å±¥æ­·"""
    text = extract_text_from_pdf(pdf_path)
    if not text:
        return None
    
    name = extract_name(text)
    position = extract_position(text)
    skills = extract_skills(text)
    
    filename = Path(pdf_path).name
    file_id = filename.split('---')[0] if '---' in filename else filename.replace('.pdf', '')
    
    return {
        'name': name,
        'contact': 'å¾…è£œå……',
        'position': position,
        'skills': skills,
        'experience_years': 'å¾…ç¢ºèª',
        'education': 'å¾…ç¢ºèª',
        'file_link': file_id,
        'status': 'PDFå·²è§£æ',
        'consultant': 'Jacky',
        'notes': 'LinkedInå…¬é–‹æœå°‹å€™é¸äºº',
        'created_date': '2026-02-12',
        'updated_date': '2026-02-12'
    }

def main():
    # æ‰¾å‡ºæ‰€æœ‰ PDF æ–‡ä»¶
    pdf_dir = Path('/Users/user/clawd/hr-recruitment/candidates/cambodia-finance/å¾…åˆ†ç±»-ç¨åå¤„ç†')
    pdf_files = list(pdf_dir.glob('*.pdf'))
    
    print(f"ğŸ“‚ æ‰¾åˆ° {len(pdf_files)} å€‹ PDF æ–‡ä»¶")
    
    # éæ¿¾å·²è™•ç†çš„
    unprocessed = [
        f for f in pdf_files 
        if not any(proc in f.name for proc in PROCESSED_FILES)
    ]
    
    print(f"ğŸ“ å¾…è™•ç†ï¼š{len(unprocessed)} å€‹")
    
    results = []
    for i, pdf_path in enumerate(unprocessed, 1):
        print(f"[{i}/{len(unprocessed)}] è§£æ {pdf_path.name}...", end=' ')
        
        candidate = parse_resume(str(pdf_path))
        if candidate:
            results.append(candidate)
            print(f"âœ“ {candidate['name']}")
        else:
            print("âœ— å¤±æ•—")
    
    # è¼¸å‡º JSONï¼ˆä¾› Google Sheets åŒ¯å…¥ï¼‰
    output_path = '/tmp/batch-parsed-resumes.json'
    
    # è½‰æ›æˆ Google Sheets æ ¼å¼
    sheet_data = [
        [
            c['name'], c['contact'], c['position'], c['skills'],
            c['experience_years'], c['education'], c['file_link'],
            c['status'], c['consultant'], c['notes'],
            c['created_date'], c['updated_date']
        ]
        for c in results
    ]
    
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(sheet_data, f, ensure_ascii=False, indent=2)
    
    print(f"\nâœ… å®Œæˆï¼å…±è§£æ {len(results)} äºº")
    print(f"ğŸ“„ çµæœï¼š{output_path}")
    
    return results

if __name__ == '__main__':
    main()
