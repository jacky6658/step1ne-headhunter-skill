#!/bin/bash
# è™•ç† BDå®¢æˆ¶é–‹ç™¼è¡¨ä¸­æ²’æœ‰ 104 URL çš„å…¬å¸

set -e

SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
SHEET_ID="1bkI7_cCh_Bs4qVa3HlXiy0CFzmItZlA-DYGHSPS4InE"
GOG_ACCOUNT="aiagentg888@gmail.com"

GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m'

echo -e "${BLUE}ðŸ“‹ è®€å– BDå®¢æˆ¶é–‹ç™¼è¡¨...${NC}"
gog sheets get "$SHEET_ID" 'å·¥ä½œè¡¨1!A:E' --json --account "$GOG_ACCOUNT" > /tmp/bd-missing-raw.json

echo -e "${BLUE}ðŸ” æ‰¾å‡ºæ²’æœ‰ 104 URL çš„å…¬å¸...${NC}"

cat > /tmp/find-missing-companies.py << 'EOF'
#!/usr/bin/env python3
import json

with open('/tmp/bd-missing-raw.json', 'r', encoding='utf-8') as f:
    data = json.load(f)

companies = []
rows = data.get('values', [])

for i, row in enumerate(rows[1:], 2):
    if len(row) >= 1:
        company_name = row[0].strip() if row[0] else ""
        company_url = row[4].strip() if len(row) > 4 and row[4] else ""
        
        # åªè™•ç†ï¼šæœ‰å…¬å¸åç¨± ä¸” (æ²’æœ‰URL æˆ– URL="å¾…æŸ¥" æˆ– URL æ˜¯éŒ¯èª¤çš„æœå°‹é é¢)
        if company_name and (not company_url or company_url == "å¾…æŸ¥" or "company/search" in company_url):
            companies.append({
                "row": i,
                "company": company_name
            })

print(json.dumps(companies, ensure_ascii=False, indent=2))
EOF

python3 /tmp/find-missing-companies.py > /tmp/missing-companies.json

count=$(cat /tmp/missing-companies.json | jq '. | length')
echo -e "${GREEN}âœ… æ‰¾åˆ° ${count} å®¶æ²’æœ‰ 104 URL çš„å…¬å¸${NC}"

if [[ $count -eq 0 ]]; then
    echo "æ²’æœ‰éœ€è¦è™•ç†çš„å…¬å¸"
    exit 0
fi

echo -e "${YELLOW}è¦è™•ç†çš„å…¬å¸ï¼š${NC}"
cat /tmp/missing-companies.json | jq -r '.[] | "  Row \(.row): \(.company)"'
echo ""

# å»ºç«‹çˆ¬èŸ²è…³æœ¬
cat > /tmp/search-and-fill-companies.py << 'EOFPY'
#!/usr/bin/env python3
import subprocess
import re
import json
from datetime import datetime

def log_debug(message):
    with open("/tmp/missing-companies-debug.log", 'a', encoding='utf-8') as log:
        log.write(f"[{datetime.now()}] {message}\n")

def search_104_company(company_name):
    """åœ¨ 104 æœå°‹å…¬å¸åç¨±ï¼Œæ‰¾åˆ°å…¬å¸é é¢ URL"""
    log_debug(f"ðŸ” æœå°‹å…¬å¸: {company_name}")
    
    # ä½¿ç”¨ 104 å…¬å¸æœå°‹
    search_url = f"https://www.104.com.tw/company/search/?keyword={company_name}"
    
    subprocess.run(['agent-browser', 'navigate', search_url], check=True, capture_output=True)
    subprocess.run(['agent-browser', 'wait', '--load', 'networkidle', '--timeout', '10000'], check=True, capture_output=True)
    
    import time
    time.sleep(2)
    
    # å–å¾— snapshot
    result = subprocess.run(['agent-browser', 'snapshot'], capture_output=True, text=True)
    
    # æ‰¾ç¬¬ä¸€å€‹çœŸæ­£çš„å…¬å¸é€£çµï¼ˆä¸æ˜¯æœå°‹é é¢ï¼‰
    for line in result.stdout.split('\n'):
        if '/url:' in line and '/company/' in line:
            match = re.search(r'/url:\s*((?:https?:)?//www\.104\.com\.tw/company/([a-z0-9]+))', line)
            if match:
                company_id = match.group(2)
                # æŽ’é™¤ search, main ç­‰éžå…¬å¸IDçš„é é¢
                if company_id not in ['search', 'main', 'list']:
                    url = match.group(1)
                    if url.startswith('//'):
                        url = f"https:{url}"
                    log_debug(f"  âœ… æ‰¾åˆ°å…¬å¸é é¢: {url}")
                    return url
    
    log_debug(f"  âŒ æœªæ‰¾åˆ°å…¬å¸é é¢")
    return None

def extract_company_contact(company_url):
    """å¾žå…¬å¸é é¢æå–è¯çµ¡è³‡è¨Š"""
    log_debug(f"ðŸ“ž è¨ªå•: {company_url}")
    
    subprocess.run(['agent-browser', 'navigate', company_url], check=True, capture_output=True)
    subprocess.run(['agent-browser', 'wait', '--load', 'networkidle', '--timeout', '10000'], check=True, capture_output=True)
    
    import time
    time.sleep(2)
    
    result = subprocess.run(['agent-browser', 'snapshot'], capture_output=True, text=True)
    lines = result.stdout.split('\n')
    
    contact_info = {
        "contact_person": None,
        "phone": None,
        "email": None,
        "website": None
    }
    
    for i, line in enumerate(lines):
        if 'heading "è¯çµ¡äºº"' in line and i+1 < len(lines):
            next_line = lines[i+1].strip()
            if '- paragraph:' in next_line:
                name = next_line.replace('- paragraph:', '').strip()
                if name and name != "æš«ä¸æä¾›":
                    contact_info['contact_person'] = name
        
        if 'heading "é›»è©±"' in line and i+1 < len(lines):
            next_line = lines[i+1].strip()
            if '- paragraph:' in next_line:
                phone = next_line.replace('- paragraph:', '').strip()
                if phone and phone != "æš«ä¸æä¾›":
                    contact_info['phone'] = phone
        
        if 'heading "å…¬å¸ç¶²å€"' in line and i+2 < len(lines):
            url_line = lines[i+2].strip()
            if '- /url:' in url_line:
                url_match = re.search(r'- /url:\s*(https?://[^\s]+)', url_line)
                if url_match:
                    contact_info['website'] = url_match.group(1).strip()
        
        if '@' in line:
            email_match = re.search(r'([\w\.-]+@[\w\.-]+\.\w+)', line)
            if email_match:
                contact_info['email'] = email_match.group(1).strip()
    
    log_debug(f"  é›»è©±: {contact_info['phone']}, Email: {contact_info['email']}")
    return contact_info

# è®€å–å…¬å¸åˆ—è¡¨
with open('/tmp/missing-companies.json', 'r', encoding='utf-8') as f:
    companies = json.load(f)

# é–‹å•Ÿç€è¦½å™¨
subprocess.run(['agent-browser', 'open', 'https://www.104.com.tw'], check=True, capture_output=True)
subprocess.run(['agent-browser', 'wait', '--load', 'networkidle', '--timeout', '10000'], check=True, capture_output=True)

log_debug(f"é–‹å§‹è™•ç† {len(companies)} å®¶å…¬å¸")

results = []

for company_data in companies:
    company_name = company_data['company']
    row = company_data['row']
    
    log_debug(f"\n{'='*60}")
    log_debug(f"ðŸ¢ è™•ç†: {company_name} (Row {row})")
    
    try:
        # æ­¥é©Ÿ 1ï¼šæœå°‹å…¬å¸æ‰¾åˆ° 104 URL
        company_url = search_104_company(company_name)
        
        if not company_url:
            results.append({
                "row": row,
                "company": company_name,
                "company_url": "æ‰¾ä¸åˆ°",
                "phone": "å¾…æŸ¥",
                "email": "å¾…æŸ¥",
                "website": ""
            })
            log_debug(f"âŒ è·³éŽ: {company_name}ï¼ˆæœªæ‰¾åˆ°å…¬å¸é é¢ï¼‰")
            continue
        
        # æ­¥é©Ÿ 2ï¼šå¾žå…¬å¸é é¢æå–è¯çµ¡è³‡è¨Š
        contact_info = extract_company_contact(company_url)
        
        results.append({
            "row": row,
            "company": company_name,
            "company_url": company_url,
            "phone": contact_info['phone'] or "å¾…æŸ¥",
            "email": contact_info['email'] or "å¾…æŸ¥",
            "website": contact_info['website'] or "",
            "contact_person": contact_info['contact_person'] or ""
        })
        
        log_debug(f"âœ… å®Œæˆ: {company_name}")
        
    except Exception as e:
        log_debug(f"âŒ å¤±æ•—: {company_name} - {e}")
        results.append({
            "row": row,
            "company": company_name,
            "company_url": "æ‰¾ä¸åˆ°",
            "phone": "å¾…æŸ¥",
            "email": "å¾…æŸ¥",
            "website": ""
        })

# é—œé–‰ç€è¦½å™¨
subprocess.run(['agent-browser', 'close'], check=True, capture_output=True)

print(json.dumps(results, ensure_ascii=False, indent=2))
log_debug(f"âœ… å…¨éƒ¨å®Œæˆï¼Œå…±è™•ç† {len(results)} å®¶å…¬å¸")
EOFPY

echo -e "${BLUE}ðŸ•·ï¸  é–‹å§‹æœå°‹ä¸¦çˆ¬å–è¯çµ¡è³‡è¨Š...${NC}"
python3 /tmp/search-and-fill-companies.py > /tmp/missing-companies-result.json

echo -e "${BLUE}ðŸ“ æ›´æ–° Google Sheets...${NC}"

cat > /tmp/update-missing-sheets.py << 'EOFUPDATE'
#!/usr/bin/env python3
import json
import subprocess

with open('/tmp/missing-companies-result.json', 'r', encoding='utf-8') as f:
    results = json.load(f)

updated = 0
for item in results:
    row = item['row']
    phone = item.get('phone', 'å¾…æŸ¥')
    email = item.get('email', 'å¾…æŸ¥')
    website = item.get('website', '')
    company_url = item.get('company_url', 'æ‰¾ä¸åˆ°')
    
    # æ›´æ–° B æ¬„ï¼ˆé›»è©±ï¼‰
    if phone and phone != "å¾…æŸ¥":
        range_phone = f"å·¥ä½œè¡¨1!B{row}"
        subprocess.run(['gog', 'sheets', 'update', '1bkI7_cCh_Bs4qVa3HlXiy0CFzmItZlA-DYGHSPS4InE', range_phone, phone, '--account', 'aiagentg888@gmail.com'], check=True, capture_output=True)
        updated += 1
    
    # æ›´æ–° C æ¬„ï¼ˆEmailï¼‰
    if email and email != "å¾…æŸ¥":
        range_email = f"å·¥ä½œè¡¨1!C{row}"
        subprocess.run(['gog', 'sheets', 'update', '1bkI7_cCh_Bs4qVa3HlXiy0CFzmItZlA-DYGHSPS4InE', range_email, email, '--account', 'aiagentg888@gmail.com'], check=True, capture_output=True)
        updated += 1
    
    # æ›´æ–° D æ¬„ï¼ˆå®˜ç¶²ï¼‰
    if website and website != "":
        range_website = f"å·¥ä½œè¡¨1!D{row}"
        subprocess.run(['gog', 'sheets', 'update', '1bkI7_cCh_Bs4qVa3HlXiy0CFzmItZlA-DYGHSPS4InE', range_website, website, '--account', 'aiagentg888@gmail.com'], check=True, capture_output=True)
        updated += 1
    
    # æ›´æ–° E æ¬„ï¼ˆ104 å…¬å¸é é¢ï¼‰
    if company_url:
        range_company_url = f"å·¥ä½œè¡¨1!E{row}"
        subprocess.run(['gog', 'sheets', 'update', '1bkI7_cCh_Bs4qVa3HlXiy0CFzmItZlA-DYGHSPS4InE', range_company_url, company_url, '--account', 'aiagentg888@gmail.com'], check=True, capture_output=True)
        updated += 1

print(f"Updated {updated} cells")
EOFUPDATE

python3 /tmp/update-missing-sheets.py

echo -e "${GREEN}âœ… å®Œæˆï¼${NC}"
echo -e "${GREEN}æŸ¥çœ‹æ›´æ–°ï¼šhttps://docs.google.com/spreadsheets/d/1bkI7_cCh_Bs4qVa3HlXiy0CFzmItZlA-DYGHSPS4InE${NC}"
