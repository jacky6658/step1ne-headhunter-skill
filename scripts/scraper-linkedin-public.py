#!/usr/bin/env python3
"""
LinkedIn å…¬é–‹å€‹äººæª”æ¡ˆçˆ¬èŸ²
ç­–ç•¥ï¼šé€é Google æœå°‹ LinkedIn å€‹äººæª”æ¡ˆ â†’ çˆ¬å–å…¬é–‹è³‡è¨Š
"""

import sys
import json
import re
import time
from urllib.parse import quote_plus
import subprocess

def google_search_linkedin(keywords, location="Taiwan", max_results=20):
    """ä½¿ç”¨ Google æœå°‹ LinkedIn å€‹äººæª”æ¡ˆ"""
    
    # å»ºç«‹æœå°‹æŸ¥è©¢
    query = f"{keywords} {location} site:linkedin.com/in"
    
    print(f"ğŸ” Google æœå°‹ï¼š{query}", file=sys.stderr)
    
    # ä½¿ç”¨ Brave Search APIï¼ˆå·²è¨­å®šï¼‰
    try:
        from web_search import web_search
        results = web_search(query, count=min(max_results, 10))
        
        linkedin_urls = []
        for result in results.get('results', []):
            url = result.get('url', '')
            if 'linkedin.com/in/' in url:
                linkedin_urls.append(url)
        
        return linkedin_urls
    except:
        # Fallbackï¼šä½¿ç”¨ curl + Google
        encoded_query = quote_plus(query)
        url = f"https://www.google.com/search?q={encoded_query}&num={max_results}"
        
        try:
            result = subprocess.run(
                ['curl', '-s', '-A', 'Mozilla/5.0', url],
                capture_output=True,
                text=True,
                timeout=10
            )
            
            # ç°¡å–®è§£æ Google çµæœé 
            html = result.stdout
            linkedin_urls = re.findall(r'https://[a-z]+\.linkedin\.com/in/[^"&<>\s]+', html)
            
            # å»é‡
            linkedin_urls = list(set(linkedin_urls))[:max_results]
            
            return linkedin_urls
        except Exception as e:
            print(f"âŒ æœå°‹å¤±æ•—ï¼š{e}", file=sys.stderr)
            return []

def extract_linkedin_info(url):
    """å¾ LinkedIn å…¬é–‹é é¢æå–è³‡è¨Šï¼ˆç°¡åŒ–ç‰ˆï¼‰"""
    
    # LinkedIn å…¬é–‹é é¢æ ¼å¼ï¼šlinkedin.com/in/username
    username = url.split('/in/')[-1].split('?')[0].strip('/')
    
    # ä½¿ç”¨ web_fetch å˜—è©¦æŠ“å–ï¼ˆä½†å¯èƒ½è¢«æ“‹ï¼‰
    try:
        result = subprocess.run(
            ['curl', '-s', '-A', 'Mozilla/5.0', url],
            capture_output=True,
            text=True,
            timeout=10
        )
        
        html = result.stdout
        
        # ç°¡å–®è§£æï¼ˆLinkedIn çµæ§‹è¤‡é›œï¼Œåªèƒ½æŠ“éƒ¨åˆ†è³‡è¨Šï¼‰
        name_match = re.search(r'<title>([^|<]+)', html)
        name = name_match.group(1).strip() if name_match else username
        
        # æ¸…ç†åç¨±
        name = name.replace(' - Taiwan', '').replace(' | LinkedIn', '').strip()
        
        return {
            'name': name,
            'linkedin_url': url,
            'username': username,
            'source': 'linkedin_public'
        }
    
    except Exception as e:
        print(f"âš ï¸  ç„¡æ³•æŠ“å– {url}: {e}", file=sys.stderr)
        return {
            'name': username,
            'linkedin_url': url,
            'username': username,
            'source': 'linkedin_public'
        }

def main():
    import argparse
    
    parser = argparse.ArgumentParser(description='LinkedIn å…¬é–‹å€‹äººæª”æ¡ˆæœå°‹')
    parser.add_argument('--keywords', required=True, help='æœå°‹é—œéµå­—ï¼ˆè·ä½ + æŠ€èƒ½ï¼‰')
    parser.add_argument('--location', default='Taiwan', help='åœ°é»')
    parser.add_argument('--max-results', type=int, default=20, help='æœ€å¤§çµæœæ•¸')
    parser.add_argument('--output', default=None, help='è¼¸å‡ºæª”æ¡ˆ')
    
    args = parser.parse_args()
    
    # æœå°‹ LinkedIn URLs
    linkedin_urls = google_search_linkedin(
        args.keywords,
        args.location,
        args.max_results
    )
    
    print(f"âœ… æ‰¾åˆ° {len(linkedin_urls)} å€‹ LinkedIn å€‹äººæª”æ¡ˆ", file=sys.stderr)
    
    # æå–è³‡è¨Š
    candidates = []
    for url in linkedin_urls:
        info = extract_linkedin_info(url)
        candidates.append(info)
        time.sleep(1)  # é¿å…è¢«æ“‹
    
    # è¼¸å‡º
    if args.output:
        with open(args.output, 'w', encoding='utf-8') as f:
            json.dump(candidates, f, ensure_ascii=False, indent=2)
        print(f"ğŸ’¾ çµæœå·²å­˜è‡³ {args.output}", file=sys.stderr)
    else:
        print(json.dumps(candidates, ensure_ascii=False, indent=2))
    
    print(f"\nâœ… å®Œæˆï¼š{len(candidates)} ä½å€™é¸äºº", file=sys.stderr)

if __name__ == '__main__':
    main()
